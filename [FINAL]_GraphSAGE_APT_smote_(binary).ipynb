{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A_hKBf36fGy",
        "outputId": "e6b32568-a5cf-475e-c1ef-449119dc6f6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adj_rus (1).npy: Shape=(189216, 2), Type=<class 'numpy.ndarray'>\n",
            "edge_feat_rus.npy: Shape=(189216, 63), Type=<class 'numpy.ndarray'>\n",
            "label_bi_rus (1).npy: Shape=(189216,), Type=<class 'numpy.ndarray'>\n",
            "node_random (1).npy: Shape=(19374,), Type=<class 'numpy.ndarray'>\n",
            "adj_random_list.dict (1): Loaded successfully, Type=<class 'collections.defaultdict'>\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "# 불러올 파일 리스트\n",
        "files = [\n",
        "     \"adj_rus (1).npy\", \"edge_feat_rus.npy\",\n",
        "    \"label_bi_rus (1).npy\",  \"node_random (1).npy\"\n",
        "]\n",
        "\n",
        "# 각 파일 로드 및 shape 확인\n",
        "for file in files:\n",
        "    try:\n",
        "        data = np.load(f\"{file}\", allow_pickle=True)\n",
        "        print(f\"{file}: Shape={data.shape}, Type={type(data)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file}: {e}\")\n",
        "\n",
        "# adj_random_list.dict 파일 로드\n",
        "try:\n",
        "    with open(f\"adj_random_list (1).dict\", \"rb\") as f:\n",
        "        adj_random_list = pickle.load(f)\n",
        "    print(f\"adj_random_list.dict (1): Loaded successfully, Type={type(adj_random_list)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading adj_random_list(1).dict: {e}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING/ ROUND 2"
      ],
      "metadata": {
        "id": "6RSdX-6RhyQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyTorch Geometric and its dependencies\n",
        "!pip install torch-scatter torch-sparse torch-geometric torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf_8JxLqZhIp",
        "outputId": "81db7fbe-dadf-4f0c-aab1-95eff4857b30"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_scatter-2.1.2%2Bpt20cpu-cp311-cp311-linux_x86_64.whl (494 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.0/494.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_sparse-0.6.18%2Bpt20cpu-cp311-cp311-linux_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_cluster-1.6.3%2Bpt20cpu-cp311-cp311-linux_x86_64.whl (750 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.9/750.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.0.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt20cpu-cp311-cp311-linux_x86_64.whl (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.15.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster, torch-geometric\n",
            "Successfully installed torch-cluster-1.6.3+pt20cpu torch-geometric-2.6.1 torch-scatter-2.1.2+pt20cpu torch-sparse-0.6.18+pt20cpu torch-spline-conv-1.2.2+pt20cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------------------------\n",
        "# Load Data\n",
        "# ---------------------------\n",
        "edge_feat = np.load(\"edge_feat_rus.npy\", allow_pickle=True)\n",
        "adj = np.load(\"adj_rus (1).npy\", allow_pickle=True)\n",
        "label = np.load(\"label_bi_rus (1).npy\")"
      ],
      "metadata": {
        "id": "UIpcBja9mVzD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"edge_feat shape:\", edge_feat.shape)\n",
        "print(\"adj shape:\", adj.shape)\n",
        "print(\"label shape:\", label.shape)\n",
        "# ---------------------------\n",
        "# Load Data\n",
        "# ---------------------------\n",
        "edge_feat = np.load(\"edge_feat_rus.npy\", allow_pickle=True)\n",
        "adj = np.load(\"adj_rus (1).npy\", allow_pickle=True)\n",
        "label = np.load(\"label_bi_rus (1).npy\")\n",
        "# Ensure edge_feat contains only numerical values\n",
        "edge_feat = edge_feat.astype(np.float32)  # Convert to float32\n",
        "\n",
        "# Reduce Dataset Size: Sample 5% of Data\n",
        "subset_size = 0.05  # Use only 5% of data\n",
        "sample_indices, _ = train_test_split(np.arange(len(label)), train_size=subset_size, stratify=label, random_state=42)\n",
        "\n",
        "# Apply sampling\n",
        "edge_feat = edge_feat[sample_indices]\n",
        "label = label[sample_indices]\n",
        "\n",
        "# ---------------------------\n",
        "# Fix Adjacency Index Mapping Issue\n",
        "# ---------------------------\n",
        "# Find unique nodes that remain in the sampled dataset\n",
        "valid_nodes = set(np.unique(edge_feat))  # Nodes that exist in feature matrix\n",
        "node_mapping = {node: i for i, node in enumerate(valid_nodes)}\n",
        "\n",
        "# Re-map adjacency list indices to match the reduced dataset\n",
        "adj_remapped = []\n",
        "for src, dst in adj[sample_indices]:\n",
        "    if src in node_mapping and dst in node_mapping:  # Only keep valid edges\n",
        "        adj_remapped.append([node_mapping[src], node_mapping[dst]])\n",
        "\n",
        "# Convert adj to NumPy array and PyTorch tensor\n",
        "adj_numeric = np.array(adj_remapped, dtype=np.int64)\n",
        "adj_numeric = torch.tensor(adj_numeric, dtype=torch.long)\n",
        "\n",
        "# Convert Labels to One-Hot Encoding\n",
        "num_classes = int(label.max()) + 1  # Get number of unique classes\n",
        "label_one_hot = np.eye(num_classes)[label.astype(int)]  # Convert to one-hot encoding\n",
        "label = torch.tensor(label_one_hot, dtype=torch.float32)  # Convert to PyTorch tensor\n",
        "\n",
        "# Convert Node Features to PyTorch Tensor\n",
        "edge_feat = torch.tensor(edge_feat, dtype=torch.float32)\n",
        "\n",
        "# ---------------------------\n",
        "# GNN Model Definition\n",
        "# ---------------------------\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_feats, hidden_feats, out_feats, dropout=0.5):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.fc1 = nn.Linear(in_feats*2, hidden_feats)\n",
        "        self.fc2 = nn.Linear(hidden_feats*2, out_feats)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def aggregate(self, x, edge_index):\n",
        "        if edge_index.dim() == 1:\n",
        "            edge_index = edge_index.view(-1, 2)\n",
        "\n",
        "        src, dst = edge_index[:, 0], edge_index[:, 1]\n",
        "\n",
        "        # Mask to avoid out-of-range indices\n",
        "        valid_mask = (src < x.size(0)) & (dst < x.size(0))\n",
        "        if valid_mask.sum() == 0:\n",
        "            return x\n",
        "\n",
        "        agg = torch.zeros_like(x)\n",
        "        agg.index_add_(0, dst[valid_mask], x[src[valid_mask]])  # Sum of neighbor features\n",
        "        return agg\n",
        "\n",
        "    def forward(self, x, edge_index): #x is node feature, edge_index is edge list\n",
        "        # First layer\n",
        "        neighbor_agg = self.aggregate(x, edge_index)\n",
        "        h = torch.cat([x, neighbor_agg], dim=1)\n",
        "        h = self.fc1(h)\n",
        "        h = F.relu(h)\n",
        "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "\n",
        "        # Second layer\n",
        "        neighbor_agg = self.aggregate(h, edge_index)\n",
        "        h = torch.cat([h, neighbor_agg], dim=1)\n",
        "        h = self.fc2(h)\n",
        "        return torch.sigmoid(h)\n",
        "\n",
        "# ---------------------------\n",
        "# Initialize Model, Loss, Optimizer\n",
        "# ---------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_features = edge_feat.shape[1]\n",
        "num_classes = label.shape[1]  # Correct way to get the number of labels\n",
        "\n",
        "model = GraphSAGE(in_feats=num_features, hidden_feats=128, out_feats=num_classes).to(device)\n",
        "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for multi-label classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "# ---------------------------\n",
        "# Train-Test Split on Reduced Dataset\n",
        "# ---------------------------\n",
        "train_idx, test_idx = train_test_split(np.arange(len(label)), test_size=0.2, random_state=42)\n",
        "train_idx, val_idx = train_test_split(train_idx, test_size=0.1, random_state=42)\n",
        "\n",
        "# Move tensors to GPU if available\n",
        "edge_feat, adj_numeric, label = edge_feat.to(device), adj_numeric.to(device), label.to(device)\n",
        "\n",
        "# ---------------------------\n",
        "# Training Loop\n",
        "# ---------------------------\n",
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    # Use tqdm for batch progress tracking\n",
        "    with tqdm(total=len(train_idx) // batch_size, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as pbar:\n",
        "        for i in range(0, len(train_idx), batch_size):\n",
        "            batch_idx = train_idx[i:i + batch_size]\n",
        "            batch_feat = edge_feat  # Use full node feature matrix\n",
        "            batch_adj = adj_numeric  # Adjacency is global, not batch-specific\n",
        "            batch_label = label[batch_idx]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_feat, batch_adj) #running the model\n",
        "            loss = criterion(outputs[batch_idx], batch_label)  # Select only batch outputs\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # Compute Accuracy\n",
        "            predicted_labels = (outputs[batch_idx] > 0.5).float()  # Convert to binary labels\n",
        "            correct_predictions += (predicted_labels == batch_label).sum().item()\n",
        "            total_samples += batch_label.numel()  # Total number of elements in labels\n",
        "\n",
        "            # Update progress bar\n",
        "            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "            pbar.update(1)\n",
        "\n",
        "    # Compute and print epoch accuracy\n",
        "    epoch_accuracy = correct_predictions / total_samples\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Avg Loss: {epoch_loss / len(train_idx):.6f}, Accuracy: {epoch_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_-oHyAabdmX",
        "outputId": "3f623829-1b3d-4d15-e8b0-e9322a76fa2d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "edge_feat shape: torch.Size([9460, 63])\n",
            "adj shape: (189216, 2)\n",
            "label shape: torch.Size([9460, 2])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 107batch [00:02, 47.10batch/s, loss=0.0062]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Avg Loss: 0.001787, Accuracy: 0.9780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 107batch [00:02, 48.03batch/s, loss=0.0070]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Avg Loss: 0.001034, Accuracy: 0.9908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 107batch [00:02, 45.67batch/s, loss=0.0072]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Avg Loss: 0.001148, Accuracy: 0.9905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 107batch [00:02, 44.32batch/s, loss=0.0041]                      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Avg Loss: 0.001006, Accuracy: 0.9909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 107batch [00:02, 47.33batch/s, loss=0.0058]                      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Avg Loss: 0.000980, Accuracy: 0.9910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 107batch [00:02, 48.12batch/s, loss=0.0109]                      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Avg Loss: 0.001107, Accuracy: 0.9906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 107batch [00:02, 48.46batch/s, loss=0.0033]                      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Avg Loss: 0.000974, Accuracy: 0.9909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 107batch [00:02, 36.81batch/s, loss=0.0071]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Avg Loss: 0.001047, Accuracy: 0.9908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 107batch [00:02, 41.93batch/s, loss=0.0051]                      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Avg Loss: 0.001024, Accuracy: 0.9908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 107batch [00:02, 46.94batch/s, loss=0.0029]                      "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Avg Loss: 0.001025, Accuracy: 0.9910\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, cohen_kappa_score, roc_auc_score\n",
        "\n",
        "# ---------------------------\n",
        "# Evaluation on Validation and Test Set\n",
        "# ---------------------------\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad(): #no backpropagation turn off all memory for updating\n",
        "    # Validation\n",
        "    val_outputs = model(edge_feat, adj_numeric) #invoke the def forward function\n",
        "    val_outputs = val_outputs[val_idx]  # Select only validation samples\n",
        "    val_labels = label[val_idx]\n",
        "\n",
        "    val_loss = criterion(val_outputs, val_labels)  # Compute validation loss\n",
        "\n",
        "    val_outputs_binary = (val_outputs > 0.5).float()  # Threshold for metrics\n",
        "\n",
        "    # Test\n",
        "    test_outputs = model(edge_feat, adj_numeric)\n",
        "    test_outputs = test_outputs[test_idx]  # Select only test samples\n",
        "    test_labels = label[test_idx]\n",
        "\n",
        "    test_loss = criterion(test_outputs, test_labels)  # Compute test loss\n",
        "\n",
        "    test_outputs_binary = (test_outputs > 0.5).float()  # Threshold for metrics\n",
        "    #float convert the boolean, True become 1, False become 0\n",
        "# ---------------------------\n",
        "# Validation Metrics\n",
        "# ---------------------------\n",
        "val_true = val_labels.cpu().numpy()\n",
        "val_pred = val_outputs_binary.cpu().numpy()\n",
        "val_outputs_proba = val_outputs.cpu().numpy()\n",
        "\n",
        "val_accuracy = accuracy_score(val_true.flatten(), val_pred.flatten())\n",
        "val_kappa = cohen_kappa_score(val_true.flatten(), val_pred.flatten())\n",
        "val_auc = roc_auc_score(val_true.flatten(), val_outputs_proba.flatten())\n",
        "\n",
        "# ---------------------------\n",
        "# Test Metrics\n",
        "# ---------------------------\n",
        "test_true = test_labels.cpu().numpy()\n",
        "test_pred = test_outputs_binary.cpu().numpy()\n",
        "test_outputs_proba = test_outputs.cpu().numpy()\n",
        "\n",
        "test_accuracy = accuracy_score(test_true.flatten(), test_pred.flatten())\n",
        "test_kappa = cohen_kappa_score(test_true.flatten(), test_pred.flatten())\n",
        "test_auc = roc_auc_score(test_true.flatten(), test_outputs_proba.flatten())\n",
        "\n",
        "# ---------------------------\n",
        "# Print Results\n",
        "# ---------------------------\n",
        "print(\"\\n--- Validation Set ---\")\n",
        "print(f\"Validation Loss: {val_loss.item():.4f}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "print(f\"Validation Cohen's Kappa: {val_kappa:.4f}\")\n",
        "print(f\"Validation AUC: {val_auc:.4f}\")\n",
        "\n",
        "print(\"\\n--- Test Set ---\")\n",
        "print(f\"Test Loss: {test_loss.item():.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test Cohen's Kappa: {test_kappa:.4f}\")\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n",
        "\n",
        "print(\"\\nTest Classification Report:\")\n",
        "print(classification_report(test_true, test_pred, zero_division=0))\n"
      ],
      "metadata": {
        "id": "l6mdEl8nmoZU",
        "outputId": "9467ce17-9c3f-4820-b1bf-4354ecadfd82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Validation Set ---\n",
            "Validation Loss: 0.0536\n",
            "Validation Accuracy: 0.9934\n",
            "Validation Cohen's Kappa: 0.9868\n",
            "Validation AUC: 0.9907\n",
            "\n",
            "--- Test Set ---\n",
            "Test Loss: 0.0528\n",
            "Test Accuracy: 0.9926\n",
            "Test Cohen's Kappa: 0.9852\n",
            "Test AUC: 0.9927\n",
            "\n",
            "Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      1022\n",
            "           1       0.99      0.99      0.99       870\n",
            "\n",
            "   micro avg       0.99      0.99      0.99      1892\n",
            "   macro avg       0.99      0.99      0.99      1892\n",
            "weighted avg       0.99      0.99      0.99      1892\n",
            " samples avg       0.99      0.99      0.99      1892\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}