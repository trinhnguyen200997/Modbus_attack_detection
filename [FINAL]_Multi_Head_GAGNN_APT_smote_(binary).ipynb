{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCuAYEKd73dn",
        "outputId": "3026fa4f-b0b8-4688-9667-ebae13281c9a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A_hKBf36fGy",
        "outputId": "1cfeb960-1fa1-461f-ecf1-52f30975e4f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adj_rus (1).npy: Shape=(189216, 2), Type=<class 'numpy.ndarray'>\n",
            "edge_feat_rus.npy: Shape=(189216, 63), Type=<class 'numpy.ndarray'>\n",
            "label_bi_rus (1).npy: Shape=(189216,), Type=<class 'numpy.ndarray'>\n",
            "node_random (1).npy: Shape=(19374,), Type=<class 'numpy.ndarray'>\n",
            "adj_random_list.dict (1): Loaded successfully, Type=<class 'collections.defaultdict'>\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "# 불러올 파일 리스트\n",
        "files = [\n",
        "     \"adj_rus (1).npy\", \"edge_feat_rus.npy\",\n",
        "    \"label_bi_rus (1).npy\",  \"node_random (1).npy\"\n",
        "]\n",
        "\n",
        "# 각 파일 로드 및 shape 확인\n",
        "for file in files:\n",
        "    try:\n",
        "        data = np.load(f\"{file}\", allow_pickle=True)\n",
        "        print(f\"{file}: Shape={data.shape}, Type={type(data)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file}: {e}\")\n",
        "\n",
        "# adj_random_list.dict 파일 로드\n",
        "try:\n",
        "    with open(f\"adj_random_list (1).dict\", \"rb\") as f:\n",
        "        adj_random_list = pickle.load(f)\n",
        "    print(f\"adj_random_list.dict (1): Loaded successfully, Type={type(adj_random_list)}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading adj_random_list(1).dict: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------------------------\n",
        "# Load Data\n",
        "# ---------------------------\n",
        "edge_feat = np.load(\"edge_feat_rus.npy\", allow_pickle=True)\n",
        "adj = np.load(\"adj_rus (1).npy\", allow_pickle=True)\n",
        "label = np.load(\"label_bi_rus (1).npy\")\n"
      ],
      "metadata": {
        "id": "wYEktuA8IrXq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"edge_feat shape:\", edge_feat.shape)\n",
        "print(\"adj shape:\", adj.shape)\n",
        "print(\"label shape:\", label.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTpFICKUbWXA",
        "outputId": "5ce420d7-d6a9-4d23-e3d3-02f4098cead1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "edge_feat shape: (189216, 63)\n",
            "adj shape: (189216, 2)\n",
            "label shape: (189216,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, cohen_kappa_score, roc_auc_score, classification_report\n",
        "\n",
        "# ---------------------------\n",
        "# Load Data\n",
        "# ---------------------------\n",
        "edge_feat = np.load(\"edge_feat_rus.npy\", allow_pickle=True)\n",
        "adj = np.load(\"adj_rus (1).npy\", allow_pickle=True)\n",
        "label = np.load(\"label_bi_rus (1).npy\")"
      ],
      "metadata": {
        "id": "DnLsGBD8bx8-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "edge_feat = edge_feat.astype(np.float32)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "edge_feat = scaler.fit_transform(edge_feat)\n",
        "\n",
        "# Reduce Dataset Size: Sample 5% of Data\n",
        "subset_size = 0.05\n",
        "sample_indices, _ = train_test_split(\n",
        "    np.arange(len(label)), train_size=subset_size, stratify=label, random_state=42\n",
        ")\n",
        "\n",
        "edge_feat = edge_feat[sample_indices]\n",
        "label = label[sample_indices]\n",
        "\n",
        "# Fix Adjacency Index Mapping Issue\n",
        "valid_nodes = set(np.unique(edge_feat))\n",
        "node_mapping = {node: i for i, node in enumerate(valid_nodes)}\n",
        "\n",
        "adj_remapped = []\n",
        "for src, dst in adj[sample_indices]:\n",
        "    if src in node_mapping and dst in node_mapping:\n",
        "        adj_remapped.append([node_mapping[src], node_mapping[dst]])\n",
        "\n",
        "adj_numeric = np.array(adj_remapped, dtype=np.int64)\n",
        "\n",
        "# One-hot encode labels\n",
        "num_classes = int(label.max()) + 1\n",
        "label_one_hot = np.eye(num_classes)[label.astype(int)]\n",
        "label = torch.tensor(label_one_hot, dtype=torch.float32)\n",
        "\n",
        "# Convert features to PyTorch tensor\n",
        "edge_feat = torch.tensor(edge_feat, dtype=torch.float32)\n",
        "\n",
        "# ---------------------------\n",
        "# Multi-Head GAGNN (based on GitHub repo)\n",
        "# ---------------------------\n",
        "class MultiHeadGAGNN(nn.Module):\n",
        "    def __init__(self, in_feats, hidden_feats, out_feats, num_heads=8, dropout=0.5):\n",
        "        super(MultiHeadGAGNN, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.hidden_feats = hidden_feats\n",
        "\n",
        "\n",
        "         # Adding more layers (e.g., two layers)\n",
        "        self.fc_in = nn.Linear(in_feats, hidden_feats)\n",
        "        self.attention1 = nn.MultiheadAttention(embed_dim=hidden_feats, num_heads=num_heads, dropout=dropout, batch_first=True)\n",
        "        self.attention2 = nn.MultiheadAttention(embed_dim=hidden_feats, num_heads=num_heads, dropout=dropout, batch_first=True)\n",
        "        self.fc_out = nn.Linear(hidden_feats, out_feats)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc_in(x)\n",
        "        x = x.unsqueeze(0)  # Add batch dimension for MultiheadAttention\n",
        "        attn_output1, _ = self.attention1(x, x, x)\n",
        "        attn_output2, _ = self.attention2(attn_output1, attn_output1, attn_output1)\n",
        "        attn_output = attn_output2.squeeze(0)  # Remove batch dimension\n",
        "        out = self.fc_out(attn_output)\n",
        "        out = torch.sigmoid(out)  # Multi-label prediction\n",
        "        return out\n",
        "# ---------------------------\n",
        "# Initialize Model, Loss, Optimizer\n",
        "# ---------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_features = edge_feat.shape[1]\n",
        "num_classes = label.shape[1]\n",
        "\n",
        "model = MultiHeadGAGNN(in_feats=num_features, hidden_feats=128, out_feats=num_classes).to(device)\n",
        "\n",
        "#---\n",
        "class LabelSmoothingBCELoss(nn.Module):\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        super(LabelSmoothingBCELoss, self).__init__()\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def forward(self, y_pred, y_true):\n",
        "        y_true = y_true * (1 - self.smoothing) + (1 - y_true) * self.smoothing\n",
        "        return F.binary_cross_entropy(y_pred, y_true)\n",
        "\n",
        "criterion = LabelSmoothingBCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay =1e-5)\n",
        "\n",
        "edge_feat, label = edge_feat.to(device), label.to(device)\n",
        "\n",
        "# ---------------------------\n",
        "# Train-Test Split\n",
        "# ---------------------------\n",
        "train_idx, test_idx = train_test_split(\n",
        "    np.arange(len(label)), test_size=0.2, random_state=42\n",
        ")\n",
        "train_idx, val_idx = train_test_split(\n",
        "    train_idx, test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "# ---------------------------\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, verbose=True)\n",
        "\n",
        "# Training Loop\n",
        "# ---------------------------\n",
        "num_epochs = 20\n",
        "batch_size = 64\n",
        "\n",
        "train_data = TensorDataset(edge_feat[train_idx], label[train_idx])\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch_feat, batch_label in train_loader:\n",
        "        batch_feat = batch_feat.to(device)\n",
        "        batch_label = batch_label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_feat)\n",
        "        loss = criterion(outputs, batch_label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        predicted_labels = (outputs > 0.5).float()\n",
        "        correct_predictions += (predicted_labels == batch_label).sum().item()\n",
        "        total_samples += batch_label.numel()\n",
        "\n",
        "    epoch_accuracy = correct_predictions / total_samples\n",
        "\n",
        "    # Validation after each epoch\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(edge_feat[val_idx])\n",
        "        val_labels = label[val_idx]\n",
        "        val_predicted = (val_outputs > 0.5).float()\n",
        "        val_correct = (val_predicted == val_labels).sum().item()\n",
        "        val_total = val_labels.numel()\n",
        "        val_accuracy = val_correct / val_total\n",
        "        val_loss = criterion(val_outputs, val_labels).item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_idx):.6f}, \"\n",
        "          f\"Train Accuracy: {epoch_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "    scheduler.step(val_loss)\n",
        "# ---------------------------"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUsBHcztkRyn",
        "outputId": "bdfa3b9a-2750-4ded-b0cd-5dbe3eaf27b9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.010886, Train Accuracy: 0.5240, Val Accuracy: 0.5244\n",
            "Epoch 2/20, Loss: 0.008931, Train Accuracy: 0.7565, Val Accuracy: 0.9894\n",
            "Epoch 3/20, Loss: 0.006632, Train Accuracy: 0.9781, Val Accuracy: 0.9921\n",
            "Epoch 4/20, Loss: 0.006115, Train Accuracy: 0.9817, Val Accuracy: 0.9934\n",
            "Epoch 5/20, Loss: 0.006086, Train Accuracy: 0.9796, Val Accuracy: 0.9921\n",
            "Epoch 6/20, Loss: 0.005866, Train Accuracy: 0.9807, Val Accuracy: 0.9934\n",
            "Epoch 7/20, Loss: 0.005535, Train Accuracy: 0.9893, Val Accuracy: 0.9934\n",
            "Epoch 8/20, Loss: 0.005516, Train Accuracy: 0.9899, Val Accuracy: 0.9934\n",
            "Epoch 9/20, Loss: 0.005500, Train Accuracy: 0.9902, Val Accuracy: 0.9934\n",
            "Epoch 10/20, Loss: 0.005507, Train Accuracy: 0.9890, Val Accuracy: 0.9934\n",
            "Epoch 11/20, Loss: 0.005460, Train Accuracy: 0.9906, Val Accuracy: 0.9934\n",
            "Epoch 12/20, Loss: 0.005464, Train Accuracy: 0.9899, Val Accuracy: 0.9934\n",
            "Epoch 13/20, Loss: 0.005462, Train Accuracy: 0.9904, Val Accuracy: 0.9934\n",
            "Epoch 14/20, Loss: 0.005434, Train Accuracy: 0.9910, Val Accuracy: 0.9934\n",
            "Epoch 15/20, Loss: 0.005446, Train Accuracy: 0.9905, Val Accuracy: 0.9934\n",
            "Epoch 16/20, Loss: 0.005443, Train Accuracy: 0.9909, Val Accuracy: 0.9934\n",
            "Epoch 17/20, Loss: 0.005437, Train Accuracy: 0.9906, Val Accuracy: 0.9934\n",
            "Epoch 18/20, Loss: 0.005435, Train Accuracy: 0.9910, Val Accuracy: 0.9934\n",
            "Epoch 19/20, Loss: 0.005434, Train Accuracy: 0.9908, Val Accuracy: 0.9934\n",
            "Epoch 20/20, Loss: 0.005436, Train Accuracy: 0.9908, Val Accuracy: 0.9934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, cohen_kappa_score, roc_auc_score, f1_score, classification_report\n",
        "\n",
        "# ---------------------------\n",
        "# Evaluation on Test Set\n",
        "# ---------------------------\n",
        "model.eval()\n",
        "test_data = TensorDataset(edge_feat[test_idx], label[test_idx])\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "test_loss = 0.0\n",
        "correct_predictions = 0\n",
        "total_samples = 0\n",
        "y_true = []\n",
        "y_pred_bin = []\n",
        "y_pred_prob = []"
      ],
      "metadata": {
        "id": "RbFYt1NJGgnT"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Efficient evaluation loop\n",
        "for batch_feat, batch_label in test_loader:\n",
        "    batch_feat = batch_feat.to(device)\n",
        "    batch_label = batch_label.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(batch_feat)\n",
        "        loss = criterion(outputs, batch_label)\n",
        "\n",
        "    test_loss += loss.item()\n",
        "    predicted_labels = (outputs > 0.5).float()\n",
        "    correct_predictions += (predicted_labels == batch_label).sum().item()\n",
        "    total_samples += batch_label.numel()\n",
        "\n",
        "    # Collect true and predicted labels for metrics\n",
        "    y_true.append(batch_label.cpu().numpy())\n",
        "    y_pred_bin.append(predicted_labels.cpu().numpy())\n",
        "    y_pred_prob.append(outputs.cpu().numpy())"
      ],
      "metadata": {
        "id": "kGkMwR5NGh4H"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = correct_predictions / total_samples\n",
        "y_true = np.concatenate(y_true)\n",
        "y_pred_bin = np.concatenate(y_pred_bin)\n",
        "y_pred_prob = np.concatenate(y_pred_prob)"
      ],
      "metadata": {
        "id": "Mg2OetfxGlVR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print test results\n",
        "print(f\"Test Loss: {test_loss / len(test_loader):.6f}, Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Detailed Evaluation Metrics\n",
        "# ---------------------------\n",
        "\n",
        "print(f\"\\n[Detailed Test Metrics]\")\n",
        "print(f\"Test Accuracy (sklearn): {accuracy_score(y_true.flatten(), y_pred_bin.flatten()):.4f}\")\n",
        "#print(f\"Test F1 Score (Macro): {f1_score(y_true.flatten(), y_pred_bin.flatten(), average='macro'):.4f}\")\n",
        "print(f\"Test Cohen's Kappa: {cohen_kappa_score(y_true.flatten(), y_pred_bin.flatten()):.4f}\")\n",
        "print(f\"Test AUC-ROC (Macro): {roc_auc_score(y_true, y_pred_prob, average='macro'):.4f}\")\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Evaluate the model on test set\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(edge_feat[test_idx])\n",
        "    test_labels = label[test_idx]\n",
        "    test_preds = (torch.sigmoid(test_outputs) > 0.5).float()\n",
        "\n",
        "# Print classification report\n",
        "#print(classification_report(test_labels.cpu().numpy(), test_preds.cpu().numpy(), target_names=[str(i) for i in range(num_classes)]))\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred_bin, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMIIQPXYGoYk",
        "outputId": "dcf96ef2-e4ce-4df9-ebd4-acd2a3ff7918"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.393681, Test Accuracy: 0.9926\n",
            "\n",
            "[Detailed Test Metrics]\n",
            "Test Accuracy (sklearn): 0.9926\n",
            "Test Cohen's Kappa: 0.9852\n",
            "Test AUC-ROC (Macro): 0.9908\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      1022\n",
            "           1       0.99      0.99      0.99       870\n",
            "\n",
            "   micro avg       0.99      0.99      0.99      1892\n",
            "   macro avg       0.99      0.99      0.99      1892\n",
            "weighted avg       0.99      0.99      0.99      1892\n",
            " samples avg       0.99      0.99      0.99      1892\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}